---
title: "Case-study"
output:
  html_notebook: default
  html_document: default
---

In this case study, we will analyse some data with height and weight measurements of children at birth, and again at about the ages of 2 and 9. We will tidy the data a little bit, compute some new variables, explore the data through visualization, and try some hypothesis testing and modelling. Specifically, we will investigate whether BMI at birth has an effect on BMI later at the ages of 2 and 9.

First, we install some packages we will need, if we don't have them installed already. The "tidyverse" package installs several packages in the "tidyverse" ecosystem, including "tibble", "readr" and "ggplot2".

```{r eval=FALSE}
install.packages('tidyverse')  # Installs several packages from the tidyverse ecosystem.
install.packages('magrittr')
install.packages('devtools')
```

Next, we load the packages we need.

```{r}
library(readxl)  # Reading Excel files.
library(tibble)  # The "tibble" datastructure.
library(dplyr)  # Working with the tibble datastructure.
library(ggplot2)  # Plotting.
library(lubridate)  # Working with datetime objects.
library(magrittr)  # Need this for the %>% operator.
library(devtools)  # For printing the session info at the end of the notebook.
```

# Read and pre-process data

First we read the data from an Excel file. Below, we pass the relative path to the `read_xlsx()` function; in this case, the file is in our current working directory.

```{r}
data = read_xlsx("weight_height_data.xlsx")
```

The `read_xlsx()` function reads the Excel file and stores the data in a tibble object which we name `data`. The data is stored in the memory of the computer, and any changes made to `data` are only stored in memory. If you want to save the changes you make to the data, write the data to disk using, for example, the `write_csv()` function.

Below, we use the `head()` function to inspect the top rows of the data. We also see the column names (such as "Gender" and "Date of birth") and the data type (such as `<chr>` and `<S3: POSIXct>`). Note that the `<S3: POSIXct>` data type means that "Date of birth" is stored as a kind of "datetime" object, while the other dates in the data, "Exam_day1" and "Exam_day2", are not; this is because the dates are formatted differently and R only recognized the formatting of "Date of birth" and automatically converted the date.



```{r}
head(data)
```

While these column names are intuitive, they are somewhat cumbersome to write (and we will be writing them a lot). So let's change the names using the `rename()` function. Note that we could use the syntax `rename(data, "new variable name" = "old variable name")`, but instead we are using the syntax `data %>% rename("new variable name" = "old variable name")`, where `%>%` is the *pipe* operator from the `magrittr` package.

```{r}
data = data %>% rename("ID" = "Identification number", "birth" = "Date of birth", "gender" = "Gender",
              "w0" = "Weight_birth", "h0" = "Height_birth", "exam1" = "Exam_day1", "h1" = "Height_1",
              "w1" = "Weight_1", "exam2" = "Exam_day2", "h2" = "Height_2", "w2" = "Weight_2")
```

Let's inspect the data one more time with the new column names.

```{r}
head(data)
```

Note that the birth weight is in grams, while the units are in kilograms, so we will convert the birth weight. We do this using the `mutate()` function. Note that we could have used the syntax `mutate(data, w0=w0/1000)`, but instead we use the *pipe* operator from `magrittr` to pass the data to the `mutate()` function. We also use the codes "m" and "f" for male and female, as a shorthand.

We also convert the height measures to meters, just because we want to compute BMI, which unit is $kg/m^2$.

```{r}
# Convert birth weight from grams to kilograms, to match the other weight units.
data = data %>% mutate(w0=w0/1000)
# Convert height measures to meters.
data = data %>% mutate(h0=h0/100)
data = data %>% mutate(h1=h1/100)
data = data %>% mutate(h2=h2/100)
# Represent gender as "m" and "f".
data = data %>% mutate(gender=recode(gender, "Male" = "m", "Female" = "f"))
```

We want to know the ages of the children at exam day 1 and 2. Unfortunately, working with dates can be a hassle, because of irregular formatted dates, and not completely straight-forward math in computing the differences. Luckily, the `lubridate` package makes things (relatively) easy for us.

First, let's convert all the dates to the same format using the `ymd()` ("year-month-day") and `dmy()` ("day-month-year") functions from `lubridate`.

```{r}
# Convert all dates to lubridate's "Date" objects.
data = data %>% mutate(birth=ymd(birth))
data = data %>% mutate(exam1=dmy(exam1))
data = data %>% mutate(exam2=dmy(exam2))
# We show what the data type is for the dates.
class(data %>% pull(birth))
```

Now we want to compute new variables in the data representing the ages. To compute the age, we use the `interval()` function, convert the interval to a "duration" (in the lingo of `lubridate`), and then convert that into a numberic value representing years as a floating point number.

```{r}
# Convert to an "interval" object, then to a "duration" object, and finally to a numeric value representing the number of years as a floating point.
data = data %>% mutate(age1=interval(birth, exam1) %>%
                  as.duration(.) %>%
                  as.numeric(., "years"))
# Do the same for exam day 2.
data = data %>% mutate(age2=interval(birth, exam2) %>%
                  as.duration(.) %>%
                  as.numeric(., "years"))
```

Next, let's compute the BMI of the children at birth, and at exam days 1 and 2, defined as $BMI = \frac{weight}{height^2}$. We print the head of the dataset again to see the changes.

```{r}
# Compute BMI at birth and at exam days 1 and 2, and add columns to data.
data = data %>% add_column(bmi0=data$w0/data$h0^2,
                  bmi1=data$w1/data$h1^2,
                  bmi2=data$w2/data$h2^2)
head(data)
```


# Exploratory data analysis

In this section, we will visualize the data, in order to get an overview of the data, to possibly pre-process the data further if necessary, and do some initial investigation of our hypothesis that BMI at birth influences BMI later in life.

## Distributions of age, weight, height and BMI

Before we plot anything, we need a script called "multiplot" from cookbook-r.com. This script allows us to make multiple plots in a row, a column, or in a grid.

> Multiplot:
>
> http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/

```{r}
source("multiplot.R")
```

First we are going to make boxplots of some of our variables. These will give us insight into the distribution of the data and potential outliers. Below we plot the ages at exam days 1 and 2. Note that we ignore missing data (`NA` values) in the plot, but include NA counts, so that we are aware that these may influence our data.

We use the `summarize()` function to count the number of NA values, and *pull* the number from the resulting tibble.

We use `na.rm=TRUE` to ignore NA values, which is an option in many functions in many packages in R.

The boxplot shows the median, the 25% and 75% quantiles, and the most extreme values within the quantiles plus 1.5 * IQR (see here for more info on IQR: https://en.wikipedia.org/wiki/Interquartile_range). Most notably, we see here that there are quite a few missing values, and more on the second exam day than the first. We have a somewhat extreme outlier in the second exam day with a 3 year old child; we will filter this observation later.

```{r fig.width=10, fig.height=5}
# Count NA values in age1 and age2.
na_count1 = data %>% summarize(na_count=sum(is.na(age1))) %>% pull()
na_count2 = data %>% summarize(na_count=sum(is.na(age2))) %>% pull()

# Make a botplox of age1. Set x='' to ignore label. set na.rm=TRUE to ignore NAs.
# Use sprintf to include NA count in title.
p1 = ggplot(data, aes(x='', age1)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('Age') + ggtitle(sprintf('Age at first exam day\nNA count: %d', na_count1))
# Do the same for age2.
p2 = ggplot(data, aes(x='', age2)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('') + ggtitle(sprintf('Age at second exam day\nNA count: %d', na_count2))
multiplot(p1, p2, cols=2)
```

Now we will plot the weight, height and BMI at the three time points in a similar way as we plotted age.

```{r fig.width=10, fig.height=5}
na_count0 = data %>% summarize(na_count=sum(is.na(w0))) %>% pull()
na_count1 = data %>% summarize(na_count=sum(is.na(w1))) %>% pull()
na_count2 = data %>% summarize(na_count=sum(is.na(w2))) %>% pull()

p1 = ggplot(data, aes(x='', w0)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('Weight') + ggtitle(sprintf('Weight at birth\nNA count: %d', na_count0))
p2 = ggplot(data, aes(x='', w1)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('') + ggtitle(sprintf('Weight at first exam day\nNA count: %d', na_count1))
p3 = ggplot(data, aes(x='', w2)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('') + ggtitle(sprintf('Weight at second exam day\nNA count: %d', na_count2))
multiplot(p1, p2, p3, cols=3)
```


```{r fig.width=10, fig.height=5}
na_count0 = data %>% summarize(na_count=sum(is.na(h0))) %>% pull()
na_count1 = data %>% summarize(na_count=sum(is.na(h1))) %>% pull()
na_count2 = data %>% summarize(na_count=sum(is.na(h2))) %>% pull()

p1 = ggplot(data, aes(x='', h0)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('Height') + ggtitle(sprintf('Height at birth\nNA count: %d', na_count0))
p2 = ggplot(data, aes(x='', h1)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('') + ggtitle(sprintf('Height at first exam day\nNA count: %d', na_count1))
p3 = ggplot(data, aes(x='', h2)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('') + ggtitle(sprintf('Height at second exam day\nNA count: %d', na_count2))
multiplot(p1, p2, p3, cols=3)
```



```{r fig.width=10, fig.height=5}
na_count0 = data %>% summarize(na_count=sum(is.na(bmi0))) %>% pull()
na_count1 = data %>% summarize(na_count=sum(is.na(bmi1))) %>% pull()
na_count2 = data %>% summarize(na_count=sum(is.na(bmi2))) %>% pull()

p1 = ggplot(data, aes(x='', bmi0)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('BMI') + ggtitle(sprintf('BMI at birth\nNA count: %d', na_count0))
p2 = ggplot(data, aes(x='', bmi1)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('') + ggtitle(sprintf('BMI at first exam day\nNA count: %d', na_count1))
p3 = ggplot(data, aes(x='', bmi2)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('') + ggtitle(sprintf('BMI at second exam day\nNA count: %d', na_count2))
multiplot(p1, p2, p3, cols=3)
```

## Filter outliers

We have found some outliers in the boxplots above, which we will remove partly because they will our assumption that the data is normally distributed in our modelling stage, but also because they skew summary statistics like mean and variance. The first filter we use removes children younger than 4 at the second exam day, removing one child who was 3 at this point. Note that we do not remove observations with missing values, although this would be a perfectly valid approach as well. As we can see, we only end up removing four observations using these filters.

```{r}
n_before = dim(data)[1]
data = data %>% filter(age2 > 4 | is.na(age2)) %>%
  filter(w1 < 20 | is.na(w1)) %>%
  filter(h0 < 0.9 | is.na(h0)) %>%
  filter(bmi0 > 6 | is.na(bmi0)) %>%
  filter(bmi1 < 30 | is.na(bmi1))
n_after = dim(data)[1]
print(n_before - n_after)
```


## BMI

Next we want to inspect the distribution of BMI a bit closer. First we will make histograms of our three BMI variables. We seem to have removed all outliers in the previous step, and BMI at birth looks quite normally distributed, while the distribution of BMI at the exam days looks a bit skewed.

```{r fig.width=10, fig.height=5}
ggplot(data, aes(bmi0)) +
  geom_histogram(na.rm=TRUE, bins=15) +
  ggtitle('Histogram of BMI at birth')
```


```{r fig.width=10, fig.height=5}
ggplot(data, aes(bmi1)) +
  geom_histogram(na.rm=TRUE, bins=15) +
  ggtitle('Histogram of BMI at first exam day')
```

```{r fig.width=10, fig.height=5}
ggplot(data, aes(bmi2)) +
  geom_histogram(na.rm=TRUE, bins=10) +
  ggtitle('Histogram of BMI at second exam day')
```

The qq-plot is a good way to check whether data is normally distributed. It computes theoretical quantiles based on summary statistics of the data and assuming it is normally distributed, and then compares these with the actual quantiles. The closer the points match the qq-line, the more accurately the normal distribution represents the data. In this case, BMI at birth is quite well aproximated by a normal distribution.

The QQ-plot of BMI at exam days 1 and 2 show the same story as the histogram, they don't follow the normal distribution as well as the birth BMI. The extreme ends of the distributions veer off upwards, indicating that the lower tail is heavy and the upper tail is light. However, this is still pretty close, so we will continue. If we did find that the approximation was unsatisfactory, we could try to clean up the data further, possibly by filtering, and seeing wether a transformation of the data could help.

```{r fig.width=10, fig.height=5}
ggplot(data, aes(sample=bmi0)) +
  stat_qq(na.rm=TRUE) + stat_qq_line(na.rm=TRUE) +
  ggtitle('QQ-plot of BMI at birth')
```

```{r fig.width=10, fig.height=5}
ggplot(data, aes(sample=bmi1)) +
  stat_qq(na.rm=TRUE) + stat_qq_line(na.rm=TRUE) +
  ggtitle('QQ-plot of BMI at first exam day')
```

```{r fig.width=10, fig.height=5}
ggplot(data, aes(sample=bmi1)) +
  stat_qq(na.rm=TRUE) + stat_qq_line(na.rm=TRUE) +
  ggtitle('QQ-plot of BMI at second exam day')
```

## Scatterplots

Continuing our exploratory data analysis, we can do some initial plotting to intuitively see the feasibility of our hypothesis. Let's make a scatterplot of BMI at birth against BMI at exam day 1 and 2, respectively, starting with exam day 1.

If there is an effect here, it seems very vague at a glance, and at this point in time I am skeptical whether we will find any interesting correlation. However, we will continue in the next section by modelling the data.

```{r fig.width=10, fig.height=5}
ggplot(data, aes(bmi0, bmi1)) +
  geom_point(na.rm=TRUE) +
  ggtitle("Scatterplot of BMI") + xlab("Birth") + ylab("First exam day") +
  theme(plot.title=element_text(hjust=0.5))
```

```{r fig.width=10, fig.height=5}
ggplot(data, aes(bmi0, bmi2)) +
  geom_point(na.rm=TRUE) +
  ggtitle("Scatterplot of BMI") + xlab("Birth") + ylab("Second exam day") +
  theme(plot.title=element_text(hjust=0.5))
```

# Modelling

We want to fit a linear model between the response $y$ (BMI at birth) and the explanatory variables $x$ (the exam days), with intercept $\alpha$, slope $\beta$, and assuming normally distributed noise $\epsilon$.

\[
y = \beta X + \alpha + \epsilon
\]

We use the `lm()` function to fit the linear model. We pass it the data, and a formula relating our variables of interest, and in this case, using the `~` character, we relate to R that we want a linear model of the type we have written above. R will then build the model on the data we pass it.

We use the `summary()` function to print some summary statistics for the model fit, such as the distribution of residuals, the fitted coefficients and their standard error, p-value ($Pr(>|t|)$), and so on. We note that the `bmi0` coefficient, estimated at about 0.27, means that an increase in one unit of BMI at birth leads to, on average, an increase of 0.27 in BMI at exam day 1 (about age 2). We see that the p-value for this estimate is $4.96 \cdot 10^{-9}$, making it highly significant.

```{r}
model1 = lm(bmi1 ~ bmi0, data=data)
summary(model1)
```

We compute the confidence interval as $\alpha \pm 2 se$, that is, everything within two standard deviations of the estimate, using the `confint()` function. This is a hugely important additional model summary, as it tells us the range of values our estimate is likely to take given our data. If this interval is large, then our estimate isn't all that useful, and for example, we see that our interval does not include 0, so our data provides evidence for an additive effect.

```{r}
# Compute 95% confidence interval of the "bmi0" coefficient.
confint(model1, "bmi0", 0.95)
```

Let's make a scatterplot again, this time together with the regression line. We can obtain the intercept and slope from the model, as shown below, and then we simply pass these to the `geom_abline()` function to draw the regression line.

```{r fig.width=10, fig.height=5}
# Get the intercept and slope of the regression line from the model fit.
intercept = model1$coefficients[1]
slope = model1$coefficients[2]
# Make scatterplot and regression line.
ggplot(data, aes(bmi0, bmi1)) +
  geom_point(na.rm=TRUE) +
  geom_abline(intercept=intercept, slope=slope) +
  ggtitle("Regression line of linear model") + xlab('BMI at birth') + ylab('BMI at exam day 1')
```

The last thing we want to do befor we wrap this case study up is do a little bit of model inspection by plotting the residuals. We assume that the error is normally distributed with zero mean, $\epsilon \in N(0, \sigma_{\epsilon})$. If this turns out to not be the case, then the model is a poor fit on the data, regardless of how impressive our p-values are.

Below, we plot the residuals with a boxplot, a qq-plot and a histogram, and i addition we have included the mean of the residuals in the title of the plot. We can see that the residuals are quite well approximated by a normal distribution, with mean very close to zero, and not any particularly worrying outliers. Since we have also shown that the 95% confidence interval for this estimate quite clearly indicates a additive contribution, I am confident at this point that we can say that BMI at birth does contribute to BMI at about the age of 2.

Of course, we could do a similar analysis for BMI at the second exam day, at age of about 9, but we will refrain from going through the same process one more time.

```{r fig.width=10, fig.height=5}
residuals = model1$residuals
temp = tibble(residuals=residuals)
p1 = ggplot(temp, aes(x='', residuals)) +
  geom_boxplot(na.rm=TRUE) +
  xlab('') + ylab('Residuals') + ggtitle(sprintf('Model residuals\nMean: %g', mean(residuals)))
p2 = ggplot(temp, aes(sample=residuals)) +
  stat_qq(na.rm=TRUE) + stat_qq_line(na.rm=TRUE) +
  ggtitle('')
p3 = ggplot(temp, aes(residuals)) +
  geom_histogram(na.rm=TRUE, bins=10) +
  ggtitle('')
multiplot(p1, p2, p3, cols=3)
```

To conclude this R notebook, we use the `devtools::sessions_info()` function to print information about this R session, including R version and packages loaded. This improves the reproducibility of this analysis, as without this information, package versions in particular, the code may not perform the way it is supposed to, and either produce incorrect results or not work at all.

```{r}
devtools::session_info()
```

